# ì›¹í›… ì„œëª… ê²€ì¦ í•¨ìˆ˜
import hashlib
import hmac
import logging
import time
import httpx
import jwt
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import rsa
from langchain_openai import ChatOpenAI
from langchain.schema import  SystemMessage
from dotenv import load_dotenv

load_dotenv()

from src.config.settings import (
    GITHUB_APP_ID,
    GITHUB_APP_PRIVATE_KEY,
    OPENAI_API_KEY,
    MAX_FILES_TO_ANALYZE,
    MAX_LINE_COMMENTS_PER_FILE,
    MAX_ADDED_LINES_PER_FILE_DIFF,
    MAX_REMOVED_LINES_PER_FILE_DIFF,
    MAX_PR_BODY_LENGTH_FOR_REQUIREMENTS,
    PR_BODY_SUMMARY_PREFIX_LENGTH,
    PR_BODY_SUMMARY_SUFFIX_LENGTH
)

_LOGGER = logging.getLogger(__name__)

def load_private_key_safely():
    """Private Keyë¥¼ cryptography ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì•ˆì „í•˜ê²Œ ë¡œë“œ"""
    if not GITHUB_APP_PRIVATE_KEY:
        return None

    try:
        # PEM í˜•ì‹ì˜ private keyë¥¼ ë¡œë“œ
        private_key = serialization.load_pem_private_key(
            GITHUB_APP_PRIVATE_KEY.encode('utf-8'),
            password=None
        )
        _LOGGER.info("âœ… Private Key ë¡œë“œ ì„±ê³µ")
        return private_key
    except Exception as e:
        _LOGGER.error(f"âŒ Private Key ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

# Private Key ê²€ì¦
PRIVATE_KEY_OBJECT = load_private_key_safely()

# OpenAI LLM ì´ˆê¸°í™”
try:
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3
    ) if OPENAI_API_KEY else None
except Exception as e:
    _LOGGER.warning(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    llm = None

# AI ê¸°ë°˜ ë™ì  ë¶„ì„ í”„ë¡¬í”„íŠ¸
def get_dynamic_reviewer_prompts():
    """ì‹¤ì œ ì‹œë‹ˆì–´ ê°œë°œì ìˆ˜ì¤€ì˜ ê¹Šì´ìˆëŠ” ì½”ë“œ ë¦¬ë·° í”„ë¡¬í”„íŠ¸"""

    return {
        "positive": """ë‹¹ì‹ ì€ 10ë…„ì°¨ ì‹œë‹ˆì–´ ê°œë°œì "ë´" ì…ë‹ˆë‹¤. ë³€ê²½ëœ ì½”ë“œë¥¼ ê¸ì •ì  ê´€ì ì—ì„œ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

**PR ìš”êµ¬ì‚¬í•­**: {requirements}

**ì‹¤ì œ ë³€ê²½ëœ ì½”ë“œ (diff ë¶„ì„)**:
{diff_analysis}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ **ì‹¤ì œ ì‹œë‹ˆì–´ ê°œë°œì ìˆ˜ì¤€ì˜ ì „ë¬¸ì ì¸ í”¼ë“œë°±**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **Before vs After ë¶„ì„**: ë³€ê²½ ì „í›„ ì½”ë“œë¥¼ ë¹„êµí•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì´ ê°œì„ ë˜ì—ˆëŠ”ì§€ ë¶„ì„
2. **ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„**: PR ìš”êµ¬ì‚¬í•­ê³¼ ì‹¤ì œ êµ¬í˜„ì˜ ì¼ì¹˜ë„ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ í‰ê°€
3. **ì½”ë“œ í’ˆì§ˆ í–¥ìƒì **: ì•„í‚¤í…ì²˜, ì„±ëŠ¥, ê°€ë…ì„±, ìœ ì§€ë³´ìˆ˜ì„± ê´€ì ì—ì„œ ì˜ëœ ì ì„ êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…
4. **ê¸°ìˆ ì  ìš°ìˆ˜ì„±**: ì‚¬ìš©ëœ íŒ¨í„´, ë¼ì´ë¸ŒëŸ¬ë¦¬, ì ‘ê·¼ë°©ì‹ì˜ ì¥ì ì„ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„
5. **ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: ì´ ë³€ê²½ì´ í”„ë¡œì íŠ¸ì— ë¯¸ì¹˜ëŠ” ê¸ì •ì  ì˜í–¥ ë¶„ì„

**ì¶œë ¥ í˜•ì‹**:
- ê° í¬ì¸íŠ¸ë§ˆë‹¤ ì‹¤ì œ ì½”ë“œ ë¼ì¸ì„ ì¸ìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
- 150-200ì ë‚´ì™¸ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±
- ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜ ëª…í™•í•˜ê²Œ ì„¤ëª…
- "âœ… [í•µì‹¬í‚¤ì›Œë“œ]: [êµ¬ì²´ì  ë¶„ì„ ë° ì½”ë“œ ì˜ˆì‹œ]" í˜•íƒœ

ì˜ˆì‹œ: "âœ… ì•„í‚¤í…ì²˜ ì„¤ê³„: `src/app/service/` êµ¬ì¡°ë¡œ ê³„ì¸µ ë¶„ë¦¬í•˜ì—¬ ë‹¨ì¼ ì±…ì„ ì›ì¹™ì„ ì¤€ìˆ˜. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì»¨íŠ¸ë¡¤ëŸ¬ ë¶„ë¦¬ë¡œ í…ŒìŠ¤íŠ¸ ìš©ì´ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± í¬ê²Œ í–¥ìƒë¨."
""",

        "neutral": """ë‹¹ì‹ ì€ ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸ "ë“œ" ì…ë‹ˆë‹¤. ë³€ê²½ëœ ì½”ë“œë¥¼ ì¤‘ë¦½ì ì´ê³  ë¶„ì„ì  ê´€ì ì—ì„œ ì „ë¬¸ì ìœ¼ë¡œ ê²€í† í•©ë‹ˆë‹¤.

**PR ìš”êµ¬ì‚¬í•­**: {requirements}

**ì‹¤ì œ ë³€ê²½ëœ ì½”ë“œ (diff ë¶„ì„)**:
{diff_analysis}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ **ì‹¤ì œ ì‹œë‹ˆì–´ ì•„í‚¤í…íŠ¸ ìˆ˜ì¤€ì˜ ë¶„ì„ì  í”¼ë“œë°±**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„**: ì´ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ì¥ë‹¨ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„ (ì„±ëŠ¥ vs ê°€ë…ì„±, ë³µì¡ì„± vs ìœ ì—°ì„± ë“±)
2. **í™•ì¥ì„± ê³ ë ¤ì‚¬í•­**: í–¥í›„ ê¸°ëŠ¥ ì¶”ê°€ë‚˜ ë³€ê²½ ì‹œ ì´ êµ¬ì¡°ê°€ ë¯¸ì¹  ì˜í–¥ ë¶„ì„
3. **ì˜ì¡´ì„± ë° ê²°í•©ë„**: ëª¨ë“ˆê°„ ì˜ì¡´ì„± ë³€í™”ì™€ ê²°í•©ë„ ì˜í–¥ ë¶„ì„
4. **ëŒ€ì•ˆì  ì ‘ê·¼ë²•**: ë‹¤ë¥¸ êµ¬í˜„ ë°©ì‹ê³¼ì˜ ë¹„êµ ë° í˜„ì¬ ì„ íƒì˜ íƒ€ë‹¹ì„± ê²€í† 
5. **ì ì¬ì  ê³ ë ¤ì‚¬í•­**: í˜„ì¬ëŠ” ë¬¸ì œì—†ì§€ë§Œ í–¥í›„ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ë“¤

**ì¶œë ¥ í˜•ì‹**:
- ê° ë¶„ì„ë§ˆë‹¤ êµ¬ì²´ì ì¸ ì½”ë“œ ë³€ê²½ì‚¬í•­ì„ ê·¼ê±°ë¡œ ì œì‹œ
- 150-200ì ë‚´ì™¸ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±
- ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ë¶„ì„
- "âš–ï¸ [ë¶„ì„ì˜ì—­]: [êµ¬ì²´ì  íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„ ë° ê³ ë ¤ì‚¬í•­]" í˜•íƒœ

ì˜ˆì‹œ: "âš–ï¸ ì„±ëŠ¥ vs ìœ ì§€ë³´ìˆ˜ì„±: `async/await` íŒ¨í„´ ë„ì…ìœ¼ë¡œ ë¹„ë™ê¸° ì²˜ë¦¬ ì„±ëŠ¥ì€ í–¥ìƒë˜ë‚˜, ë””ë²„ê¹… ë³µì¡ë„ ì¦ê°€. í˜„ì¬ ê·œëª¨ì—ì„œëŠ” ì ì ˆí•˜ë‚˜ íŒ€ì˜ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ìˆ™ë ¨ë„ ê³ ë ¤ í•„ìš”."
""",

        "critical": """ë‹¹ì‹ ì€ ì½”ë“œ í’ˆì§ˆ ì „ë¬¸ê°€ "ë¦¼" ì…ë‹ˆë‹¤. ë³€ê²½ëœ ì½”ë“œë¥¼ ë¹„íŒì  ê´€ì ì—ì„œ ì „ë¬¸ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ê°œì„ ì ì„ ì œì‹œí•©ë‹ˆë‹¤.

**PR ìš”êµ¬ì‚¬í•­**: {requirements}

**ì‹¤ì œ ë³€ê²½ëœ ì½”ë“œ (diff ë¶„ì„)**:
{diff_analysis}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ **ì‹¤ì œ ì‹œë‹ˆì–´ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¹„íŒì  í”¼ë“œë°±**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **ì½”ë“œ í’ˆì§ˆ ì´ìŠˆ**: ì ì¬ì  ë²„ê·¸, ì„±ëŠ¥ ë¬¸ì œ, ë³´ì•ˆ ì·¨ì•½ì ì„ êµ¬ì²´ì  ì½”ë“œì™€ í•¨ê»˜ ì§€ì 
2. **ì„¤ê³„ ì›ì¹™ ìœ„ë°˜**: SOLID, DRY, KISS ë“± ì„¤ê³„ ì›ì¹™ ìœ„ë°˜ ì‚¬í•­ê³¼ ê°œì„  ë°©ì•ˆ
3. **ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ë¯¸ì¤€ìˆ˜**: í•´ë‹¹ ì–¸ì–´/í”„ë ˆì„ì›Œí¬ì˜ ê´€ë¡€ë‚˜ ëª¨ë²” ì‚¬ë¡€ ë¯¸ì¤€ìˆ˜ ì‚¬í•­
4. **í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±**: í˜„ì¬ ì½”ë“œì˜ í…ŒìŠ¤íŠ¸ ì‘ì„± ì–´ë ¤ì›€ê³¼ ê°œì„  ë°©ì•ˆ
5. **êµ¬ì²´ì  ê°œì„  ì œì•ˆ**: ì‹¤ì œ ì½”ë“œ ì˜ˆì‹œì™€ í•¨ê»˜ ëª…í™•í•œ ê°œì„  ë°©ë²• ì œì‹œ

**ì¶œë ¥ í˜•ì‹**:
- ê° ë¬¸ì œì ë§ˆë‹¤ í•´ë‹¹ ì½”ë“œ ë¼ì¸ì„ ì •í™•íˆ ì¸ìš©
- 150-200ì ë‚´ì™¸ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±
- ë¬¸ì œì ê³¼ í•¨ê»˜ ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ
- "ğŸš¨ [ë¬¸ì œì˜ì—­]: [êµ¬ì²´ì  ë¬¸ì œì  ë° ê°œì„ ë°©ì•ˆ]" í˜•íƒœ

ì˜ˆì‹œ: "ğŸš¨ ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ì¬: `await get_installation_token()` í˜¸ì¶œ ì‹œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë‚˜ ì¸ì¦ ì‹¤íŒ¨ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬ ì—†ìŒ. `try-except`ë¡œ `httpx.RequestError` ì²˜ë¦¬í•˜ê³  ì ì ˆí•œ fallback ë¡œì§ ì¶”ê°€ í•„ìš”."
"""
    }

def validate_github_private_key():
    """GitHub App Private Key í˜•ì‹ì„ ê²€ì¦í•˜ê³  ì •ë³´ë¥¼ ì¶œë ¥"""
    if not GITHUB_APP_PRIVATE_KEY:
        _LOGGER.error("âŒ GitHub App Private Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return False

    key = GITHUB_APP_PRIVATE_KEY.strip()

    # PEM í˜•ì‹ ê²€ì¦
    if key.startswith("-----BEGIN PRIVATE KEY-----"):
        _LOGGER.info("âœ… PKCS#8 í˜•ì‹ì˜ Private Key ê°ì§€ë¨")
        return True
    elif key.startswith("-----BEGIN RSA PRIVATE KEY-----"):
        _LOGGER.info("âœ… RSA í˜•ì‹ì˜ Private Key ê°ì§€ë¨")
        return True
    elif key.startswith("-----BEGIN OPENSSH PRIVATE KEY-----"):
        _LOGGER.error("âŒ OpenSSH í˜•ì‹ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. GitHub Appì€ RSA/PKCS#8 í˜•ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤")
        return False
    else:
        _LOGGER.error(f"âŒ ì¸ì‹í•  ìˆ˜ ì—†ëŠ” Private Key í˜•ì‹: {key[:50]}...")
        return False

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ê²€ì¦
if not validate_github_private_key():
    _LOGGER.warning("âš ï¸ GitHub App Private Key ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
    _LOGGER.warning("ğŸ’¡ í˜„ì¬ SSH fingerprintê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ RSA private keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    _LOGGER.warning("ğŸ”— GitHub App ì„¤ì • í˜ì´ì§€ì—ì„œ 'Generate a private key'ë¥¼ í´ë¦­í•˜ì—¬ .pem íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")

# ì„¤ì¹˜ í† í° ë°œê¸‰ í•¨ìˆ˜
async def get_installation_token(installation_id):
    try:
        # ì„¤ì • ê²€ì¦
        if not GITHUB_APP_PRIVATE_KEY:
            _LOGGER.error("GitHub App Private Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None

        if not GITHUB_APP_ID:
            _LOGGER.error("GitHub App IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None

        # JWT ìƒì„±
        _LOGGER.info("JWT ìƒì„± ì‹œì‘")
        now = int(time.time())
        payload = {
            "iat": now,
            "exp": now + 600,  # 10ë¶„ ìœ íš¨
            "iss": int(GITHUB_APP_ID)  # App IDëŠ” ì •ìˆ˜ì—¬ì•¼ í•¨
        }

        # JWT ì„œëª…
        try:
            jwt_token = jwt.encode(payload, GITHUB_APP_PRIVATE_KEY, algorithm="RS256")
            _LOGGER.info("JWT ì„œëª… ì™„ë£Œ")
        except Exception as e:
            _LOGGER.error(f"JWT ì„œëª… ì‹¤íŒ¨: {str(e)}")
            return None

        # ì„¤ì¹˜ í† í° ìš”ì²­
        _LOGGER.info("ì„¤ì¹˜ í† í° ìš”ì²­ ì‹œì‘")
        url = f"https://api.github.com/app/installations/{installation_id}/access_tokens"
        headers = {
            "Authorization": f"Bearer {jwt_token}",
            "Accept": "application/vnd.github.v3+json"
        }

        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=headers)

            if response.status_code != 201:
                _LOGGER.error(f"í† í° ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return None

            _LOGGER.info("ì„¤ì¹˜ í† í° ìš”ì²­ ì™„ë£Œ")
            return response.json().get("token")

    except Exception as e:
        _LOGGER.error(f"í† í° ë°œê¸‰ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return None

# PR íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
async def get_pr_files(repo_name, pr_number, token):
    url = f"https://api.github.com/repos/{repo_name}/pulls/{pr_number}/files"
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    async with httpx.AsyncClient() as client:
        response = await client.get(url, headers=headers)
        response.raise_for_status()
        return response.json()

# ì–¸ì–´/í”„ë ˆì„ì›Œí¬ ê°ì§€ ë° ë¶„ì„ - AI ìœ„ì„
def analyze_project_info(payload):
    """í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ë§Œ ì¶”ì¶œ - ì–¸ì–´/í”„ë ˆì„ì›Œí¬ëŠ” AIê°€ ê°ì§€"""
    repo = payload.get("repository", {})
    pr = payload.get("pull_request", {})

    # ë³€ê²½ì‚¬í•­ í†µê³„ë§Œ ì¶”ì¶œ (AIê°€ ë‚˜ë¨¸ì§€ ë¶„ì„)
    changes = {
        "commits": pr.get("commits", 0),
        "additions": pr.get("additions", 0),
        "deletions": pr.get("deletions", 0),
        "changed_files": pr.get("changed_files", 0)
    }

    return {
        "language": "AIê°€ ê°ì§€",  # AIê°€ ë™ì ìœ¼ë¡œ ê°ì§€
        "framework": "AIê°€ ê°ì§€",  # AIê°€ ë™ì ìœ¼ë¡œ ê°ì§€
        "branch": pr.get("head", {}).get("ref", ""),
        "changes": changes,
        "description": repo.get("description", "")
    }

async def get_file_content(repo_name, file_path, token, sha=None):
    """GitHub APIë¥¼ í†µí•´ íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì˜´"""
    url = f"https://api.github.com/repos/{repo_name}/contents/{file_path}"
    if sha:
        url += f"?ref={sha}"

    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(url, headers=headers)
            if response.status_code == 200:
                import base64
                content = response.json().get("content", "")
                return base64.b64decode(content).decode('utf-8')
            return None
    except Exception as e:
        _LOGGER.error(f"íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ {file_path}: {str(e)}")
        return None

def analyze_diff_content(files):
    """ì‹¤ì œ diff ë‚´ìš©ì„ Before/After ë¹„êµ í˜•íƒœë¡œ ë¶„ì„í•˜ì—¬ AIê°€ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±"""
    diff_analysis = []

    for file in files[:MAX_FILES_TO_ANALYZE]:  # ì„¤ì •ê°’ ì‚¬ìš©
        filename = file.get("filename", "")
        patch = file.get("patch", "")
        additions = file.get("additions", 0)
        deletions = file.get("deletions", 0)
        status = file.get("status", "modified")  # added, removed, modified

        if not patch and status != "added":
            continue

        # íŒŒì¼ ìƒíƒœë³„ ë¶„ì„
        if status == "added":
            file_summary = f"""**ìƒˆ íŒŒì¼ ì¶”ê°€**: `{filename}` (+{additions} ë¼ì¸)

**ì¶”ê°€ëœ ì£¼ìš” ë‚´ìš©**:
```
{patch.split('@@')[2] if '@@' in patch else patch[:500]}...
```

**ë¶„ì„ í¬ì¸íŠ¸**: ìƒˆë¡œìš´ íŒŒì¼ ì¶”ê°€ë¡œ ì¸í•œ í”„ë¡œì íŠ¸ êµ¬ì¡° ë³€í™”, ì˜ì¡´ì„± ì˜í–¥, ë„¤ì´ë° ì»¨ë²¤ì…˜ ì¤€ìˆ˜ ì—¬ë¶€"""

        elif status == "removed":
            file_summary = f"""**íŒŒì¼ ì‚­ì œ**: `{filename}` (-{deletions} ë¼ì¸)

**ì‚­ì œ ì´ìœ  ë¶„ì„ í•„ìš”**: í•´ë‹¹ íŒŒì¼ì˜ ê¸°ëŠ¥ì´ ë‹¤ë¥¸ ê³³ìœ¼ë¡œ ì´ë™í–ˆëŠ”ì§€, ë” ì´ìƒ í•„ìš”ì—†ëŠ”ì§€ í™•ì¸ í•„ìš”"""

        else:  # modified
            # Before/After ì½”ë“œ ë¹„êµ ë¶„ì„
            before_lines = []
            after_lines = []
            context_lines = []

            lines = patch.split('\n')
            current_context = ""

            for line in lines:
                if line.startswith('@@'):
                    # í•¨ìˆ˜/í´ë˜ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    import re
                    context_match = re.search(r'@@ .* @@(.*)', line)
                    if context_match:
                        current_context = context_match.group(1).strip()
                    continue

                if line.startswith('-') and not line.startswith('---'):
                    code_line = line[1:].strip()
                    # ì˜ë¯¸ìˆëŠ” ì½”ë“œ ë³€ê²½ë§Œ í¬í•¨ (ë¹ˆ ì¤„, ë‹¨ìˆœ ê´„í˜¸, ì£¼ì„ ì œì™¸)
                    if (code_line and
                        not code_line.startswith(('#', '//', '/*', '*')) and
                        len(code_line) > 3 and
                        not code_line in ['{', '}', '(', ')', ';', ',']):
                        before_lines.append(f"  - {code_line}")

                elif line.startswith('+') and not line.startswith('+++'):
                    code_line = line[1:].strip()
                    if (code_line and
                        not code_line.startswith(('#', '//', '/*', '*')) and
                        len(code_line) > 3 and
                        not code_line in ['{', '}', '(', ')', ';', ',']):
                        after_lines.append(f"  + {code_line}")

                elif line.startswith(' ') and len(line.strip()) > 3:
                    # ì»¨í…ìŠ¤íŠ¸ ë¼ì¸ (ë³€ê²½ë˜ì§€ ì•Šì€ ì£¼ë³€ ì½”ë“œ)
                    context_lines.append(f"    {line[1:].strip()}")

            # Before/After ë¹„êµê°€ ì˜ë¯¸ìˆëŠ” ê²½ìš°ë§Œ í¬í•¨
            if before_lines or after_lines:
                file_summary = f"""**íŒŒì¼ ìˆ˜ì •**: `{filename}` (+{additions}/-{deletions})
**ì»¨í…ìŠ¤íŠ¸**: {current_context if current_context else 'ì „ì—­ ë²”ìœ„'}

**ğŸ”„ Before vs After ë¹„êµ**:

**Before (ì œê±°ëœ ì½”ë“œ)**:
```
{chr(10).join(before_lines[:MAX_REMOVED_LINES_PER_FILE_DIFF]) if before_lines else '(ì œê±°ëœ ì½”ë“œ ì—†ìŒ)'}
```

**After (ì¶”ê°€ëœ ì½”ë“œ)**:
```
{chr(10).join(after_lines[:MAX_ADDED_LINES_PER_FILE_DIFF]) if after_lines else '(ì¶”ê°€ëœ ì½”ë“œ ì—†ìŒ)'}
```

**ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸**:
```
{chr(10).join(context_lines[:3]) if context_lines else '(ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ)'}
```

**ë¶„ì„ í¬ì¸íŠ¸**: ì´ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥, ê°€ë…ì„±, ìœ ì§€ë³´ìˆ˜ì„±, í™•ì¥ì„± ì¸¡ë©´ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„ í•„ìš”"""
            else:
                continue

        diff_analysis.append(file_summary)

    return "\n\n" + "="*80 + "\n\n".join(diff_analysis) + "\n\n" + "="*80 if diff_analysis else "ë¶„ì„í•  ë§Œí•œ ìœ ì˜ë¯¸í•œ ì½”ë“œ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."

async def analyze_files_with_ai(files, project_info, repo_name, token, requirements):
    """AIë¥¼ í™œìš©í•˜ì—¬ ë³€ê²½ëœ íŒŒì¼ë“¤ì„ ë¶„ì„"""
    if not llm:
        return {
            "positive": "âœ… AI ë¶„ì„ì„ ìœ„í•œ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "neutral": "ğŸ“Š ìˆ˜ë™ ë¦¬ë·°ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
            "critical": "âš ï¸ AI ì½”ë“œ ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        }

    # ğŸ¯ ì‹¤ì œ diff ë‚´ìš© ë¶„ì„ (AIê°€ ëª¨ë“  ê²ƒì„ ë™ì ìœ¼ë¡œ)
    diff_analysis = analyze_diff_content(files)
    _LOGGER.info(f"ì‹¤ì œ diff ë¶„ì„ ì™„ë£Œ: {len(diff_analysis)} ë¬¸ì")

    # ê° ë¦¬ë·°ì–´ë³„ AI ë¶„ì„ (AIê°€ ëª¨ë“  ì–¸ì–´/í”„ë ˆì„ì›Œí¬ ê°ì§€ ë‹´ë‹¹)
    ai_reviews = {}

    for reviewer_type, prompt_template in get_dynamic_reviewer_prompts().items():
        try:
            prompt = prompt_template.format(
                requirements=requirements,
                diff_analysis=diff_analysis
            )

            response = await llm.ainvoke([SystemMessage(content=prompt)])
            ai_reviews[reviewer_type] = response.content

        except Exception as e:
            _LOGGER.error(f"AI ë¦¬ë·° ìƒì„± ì‹¤íŒ¨ ({reviewer_type}): {str(e)}")
            ai_reviews[reviewer_type] = f"ğŸš¨ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)[:100]}"

    return ai_reviews

# 3ëª…ì˜ ë¦¬ë·°ì–´ í˜ë¥´ì†Œë‚˜ ì •ì˜ (AI ê°•í™” ë²„ì „)
async def generate_reviewer_feedback_with_ai(project_info, files, repo_name, token, requirements):
    """AIë¥¼ í™œìš©í•œ 3ëª…ì˜ ë¦¬ë·°ì–´ í”¼ë“œë°± ìƒì„± - AI ì™„ì „ ìœ„ì„ ë²„ì „"""
    # AI ë¶„ì„ ì‹¤í–‰ (ëª¨ë“  ë¶„ì„ì„ AIê°€ ë‹´ë‹¹)
    ai_reviews = await analyze_files_with_ai(files, project_info, repo_name, token, requirements)

    # ê¸ì • ë¦¬ë·° ("ë´")
    positive_review = f"""## âœ… ë´ (ê¸ì •ì  ì‹œê°)
{ai_reviews.get('positive', 'í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ')}"""

    # ì¤‘ë¦½ ë¦¬ë·° ("ë“œ")
    neutral_review = f"""## âš–ï¸ ë“œ (ë¶„ì„ì  ì‹œê°)
{ai_reviews.get('neutral', 'í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ')}"""

    # ë¶€ì • ë¦¬ë·° ("ë¦¼")
    critical_review = f"""## ğŸš¨ ë¦¼ (ê°œì„ ì  ì§€ì )
{ai_reviews.get('critical', 'í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ')}"""

    return {
        "positive": positive_review,
        "neutral": neutral_review,
        "critical": critical_review
    }

# AI ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ì‘ì„± (ì‹ ê·œ)
async def create_code_review_with_requirements(repo_name, pr_number, files, token, project_info, requirements):
    """AI ì™„ì „ ìœ„ì„ ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ì‘ì„±"""
    url = f"https://api.github.com/repos/{repo_name}/pulls/{pr_number}/reviews"
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    # ğŸ¯ AI ì™„ì „ ìœ„ì„ ê¸°ë°˜ 3ëª…ì˜ ë¦¬ë·°ì–´ í”¼ë“œë°± ìƒì„±
    feedback = await generate_reviewer_feedback_with_ai(project_info, files, repo_name, token, requirements)

    # ğŸ“ AI ê¸°ë°˜ ì¸ë¼ì¸ ì½”ë©˜íŠ¸ ìƒì„±
    line_comments = await generate_ai_line_comments(files, requirements)
    _LOGGER.info(f"ìƒì„±ëœ AI ì¸ë¼ì¸ ì½”ë©˜íŠ¸: {len(line_comments)}ê°œ")

    # ì „ì²´ ë¦¬ë·° ë³¸ë¬¸ (AI ê¸°ë°˜)
    review_body = f"""# ğŸ¤– **ì‹œë‹ˆì–´ ê°œë°œì AI ì½”ë“œ ë¦¬ë·°**

## ğŸ“‹ **ë¦¬ë·° ìš”ì•½**
- **PR ìš”êµ¬ì‚¬í•­**: {requirements}
- **ë³€ê²½ ê·œëª¨**: {project_info['changes']['changed_files']}ê°œ íŒŒì¼, +{project_info['changes']['additions']}/-{project_info['changes']['deletions']} ë¼ì¸
- **ë¦¬ë·° ê´€ì **: 3ëª…ì˜ ì‹œë‹ˆì–´ ì „ë¬¸ê°€ ê´€ì  (ê¸ì •ì /ë¶„ì„ì /ë¹„íŒì )

---

## âœ… **ë´ (ì‹œë‹ˆì–´ ê°œë°œì - ê¸ì •ì  ê´€ì )**
{feedback['positive']}

---

## âš–ï¸ **ë“œ (ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸ - ë¶„ì„ì  ê´€ì )**
{feedback['neutral']}

---

## ğŸš¨ **ë¦¼ (ì½”ë“œ í’ˆì§ˆ ì „ë¬¸ê°€ - ë¹„íŒì  ê´€ì )**
{feedback['critical']}

---

## ğŸ’¡ **ë¦¬ë·° ì™„ë£Œ**
ê° ë³€ê²½ëœ ë¼ì¸ì— ëŒ€í•´ Before/After ë¹„êµ ë¶„ì„ê³¼ íŠ¸ë ˆì´ë“œì˜¤í”„ ê²€í† ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.
ì¸ë¼ì¸ ì½”ë©˜íŠ¸ì—ì„œ êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„ í™•ì¸í•˜ì„¸ìš”."""

    # GitHub API ë¦¬ë·° ë°ì´í„°
    review_data = {
        "body": review_body,
        "event": "COMMENT",
        "comments": line_comments
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=headers, json=review_data)
            response.raise_for_status()
            _LOGGER.info(f"PR #{pr_number}ì— AI ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ì‘ì„± ì™„ë£Œ")
            return True
    except Exception as e:
        _LOGGER.error(f"AI ì½”ë“œ ë¦¬ë·° ì‘ì„± ì‹¤íŒ¨: {str(e)}")
        return False

def verify_webhook_signature(payload_body, signature_header, secret):
    if not signature_header:
        return False

    hash_object = hmac.new(secret.encode('utf-8'),
                           msg=payload_body,
                           digestmod=hashlib.sha256)
    expected_signature = "sha256=" + hash_object.hexdigest()
    return hmac.compare_digest(expected_signature, signature_header)

def extract_requirements_from_pr(payload):
    """PR ì œëª©, ë³¸ë¬¸ì—ì„œ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ - AI ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°œì„ ëœ ë²„ì „"""
    pr = payload.get("pull_request", {})

    title = pr.get("title", "").strip()
    # bodyê°€ Noneì¸ ê²½ìš°ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    body = pr.get("body") or ""
    if body:
        body = body.strip()

    # ì œëª©ì€ í•„ìˆ˜ì ìœ¼ë¡œ í¬í•¨
    requirements = f"**PR ì œëª©**: {title}\n\n"

    if body:
        # ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ë°˜ ë‚´ìš© ì¶”ì¶œ ì‹œë„ (ì˜ˆì‹œ)
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”
        important_sections = []
        if "### ì£¼ìš” ë³€ê²½ ì‚¬í•­" in body:
            important_sections.append(body.split("### ì£¼ìš” ë³€ê²½ ì‚¬í•­")[1].split("###")[0].strip())
        if "### ê¸°ëŒ€ ê²°ê³¼" in body:
            important_sections.append(body.split("### ê¸°ëŒ€ ê²°ê³¼")[1].split("###")[0].strip())

        if important_sections:
            requirements += "**PR ë³¸ë¬¸ (ì£¼ìš” ë‚´ìš©)**:\n" + "\n\n".join(important_sections)
        elif len(body) > MAX_PR_BODY_LENGTH_FOR_REQUIREMENTS: # ì„¤ì •ê°’ ì‚¬ìš©
            requirements += f"**PR ë³¸ë¬¸ (ìš”ì•½)**:\n{body[:PR_BODY_SUMMARY_PREFIX_LENGTH]}...\\n...{body[-PR_BODY_SUMMARY_SUFFIX_LENGTH:]}" # ì„¤ì •ê°’ ì‚¬ìš©
        else:
            requirements += f"**PR ë³¸ë¬¸**:\n{body}"
    else:
        requirements += "PR ë³¸ë¬¸ì— ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

    if not title and not body:
        return "ìš”êµ¬ì‚¬í•­ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PR ì œëª©ì´ë‚˜ ë³¸ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    return requirements

async def handle_pull_request(payload):
    try:
        _LOGGER.info("í’€ ë¦¬í€˜ìŠ¤íŠ¸ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œì‘")

        # ğŸ¯ PR ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ (ê°„ì†Œí™”)
        requirements = extract_requirements_from_pr(payload)
        _LOGGER.info(f"ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­: {requirements}")

        # í”„ë¡œì íŠ¸ ì •ë³´ ë¶„ì„ (ê¸°ë³¸ ì •ë³´ë§Œ, AIê°€ ë‚˜ë¨¸ì§€ ë¶„ì„)
        project_info = analyze_project_info(payload)
        _LOGGER.info(f"í”„ë¡œì íŠ¸ ë¶„ì„ ì™„ë£Œ: ë³€ê²½íŒŒì¼ {project_info['changes']['changed_files']}ê°œ")

        # PR ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        pr = payload.get("pull_request", {})
        pr_number = pr.get("number")
        repo_name = payload.get("repository", {}).get("full_name")
        installation_id = payload.get("installation", {}).get("id")

        _LOGGER.info(f"PR #{pr_number} ì²˜ë¦¬ ì¤‘ - {project_info['changes']['changed_files']}ê°œ íŒŒì¼ ë³€ê²½")

        # ì•¡ì„¸ìŠ¤ í† í° ë°œê¸‰
        token = await get_installation_token(installation_id)
        if not token:
            _LOGGER.error("í† í° ë°œê¸‰ ì‹¤íŒ¨")
            return

        # PR íŒŒì¼ ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
        files = await get_pr_files(repo_name, pr_number, token)
        _LOGGER.info(f"ë³€ê²½ëœ íŒŒì¼ {len(files)}ê°œ ë¶„ì„ ì™„ë£Œ")

        #  AI ì™„ì „ ìœ„ì„ ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° ì‘ì„±!
        success = await create_code_review_with_requirements(
            repo_name, pr_number, files, token, project_info, requirements
        )

        if success:
            _LOGGER.info("AI ê¸°ë°˜ ë™ì  ì½”ë“œ ë¦¬ë·° ì‘ì„± ì„±ê³µ")
        else:
            _LOGGER.error("AI ë¦¬ë·° ì‘ì„± ì‹¤íŒ¨")

    except Exception as e:
        _LOGGER.error(f"PR ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)

async def handle_pr_notification(payload):
    """PR ê´€ë¦¬ ê´€ë ¨ ì•¡ì…˜ ì²˜ë¦¬ (assigned, review_requested ë“±)"""
    try:
        action = payload.get("action")
        pr = payload.get("pull_request", {})
        pr_number = pr.get("number")
        repo_name = payload.get("repository", {}).get("full_name")
        installation_id = payload.get("installation", {}).get("id")

        _LOGGER.info(f"PR #{pr_number} ì•Œë¦¼ ì²˜ë¦¬: {action}")

        # ì•¡ì„¸ìŠ¤ í† í° ë°œê¸‰
        token = await get_installation_token(installation_id)
        if not token:
            _LOGGER.error("í† í° ë°œê¸‰ ì‹¤íŒ¨")
            return

        # ì•¡ì…˜ë³„ ë©”ì‹œì§€ ìƒì„±
        if action == "assigned":
            assignee = payload.get("assignee", {}).get("login", "ëˆ„êµ°ê°€")
            message = f"ğŸ¯ **ë‹´ë‹¹ì í• ë‹¹ë¨**: @{assignee}ë‹˜ì´ ì´ PRì˜ ë‹´ë‹¹ìë¡œ ì§€ì •ë˜ì—ˆìŠµë‹ˆë‹¤!"
        elif action == "review_requested":
            reviewer = payload.get("requested_reviewer", {}).get("login", "ëˆ„êµ°ê°€")
            message = f"ğŸ‘€ **ë¦¬ë·° ìš”ì²­ë¨**: @{reviewer}ë‹˜ì—ê²Œ ì½”ë“œ ë¦¬ë·°ê°€ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤!"
        elif action == "ready_for_review":
            message = f"âœ… **ë¦¬ë·° ì¤€ë¹„ ì™„ë£Œ**: ì´ PRì´ ë¦¬ë·° ê°€ëŠ¥í•œ ìƒíƒœê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!"
        else:
            message = f"ğŸ“¢ **PR ì—…ë°ì´íŠ¸**: {action} ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ê°„ë‹¨í•œ ì½”ë©˜íŠ¸ ì‘ì„±
        await post_simple_comment(repo_name, pr_number, token, message)

    except Exception as e:
        _LOGGER.error(f"PR ì•Œë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)

async def post_simple_comment(repo_name, pr_number, token, message):
    """PRì— ê°„ë‹¨í•œ ì½”ë©˜íŠ¸ ì‘ì„±"""
    url = f"https://api.github.com/repos/{repo_name}/issues/{pr_number}/comments"
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    comment_data = {
        "body": message
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=headers, json=comment_data)
            response.raise_for_status()
            _LOGGER.info(f"PR #{pr_number}ì— ì•Œë¦¼ ì½”ë©˜íŠ¸ ì‘ì„± ì™„ë£Œ")
            return True
    except Exception as e:
        _LOGGER.error(f"ì•Œë¦¼ ì½”ë©˜íŠ¸ ì‘ì„± ì‹¤íŒ¨: {str(e)}")
        return False

async def generate_ai_line_comments(files, requirements):
    """AIê°€ ì‹¤ì œ ë³€ê²½ëœ ë¼ì¸ë³„ë¡œ ì •í™•í•œ ì½”ë©˜íŠ¸ ìƒì„±. íŒŒì¼ í™•ì¥ì ë° í•¨ìˆ˜/í´ë˜ìŠ¤ ì»¨í…ìŠ¤íŠ¸ í™œìš©."""
    if not llm:
        return []

    line_comments = []

    reviewer_perspectives = ["positive", "neutral", "critical"]  # ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ì  ë¦¬ìŠ¤íŠ¸
    perspective_idx = 0 # í˜„ì¬ ê´€ì  ì¸ë±ìŠ¤

    for file in files[:MAX_FILES_TO_ANALYZE]:  # ì„¤ì •ê°’ ì‚¬ìš©
        filename = file.get("filename", "")
        patch = file.get("patch", "")

        if not patch:
            continue

        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
        file_extension = filename.split('.')[-1] if '.' in filename else "unknown"

        significant_changes = []
        lines = patch.split('\n')
        current_hunk_start_line = 0
        lines_in_hunk_counter = 0
        current_context_info = "ì „ì—­ ë²”ìœ„ ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ íŒŒì•… ë¶ˆê°€" # í•¨ìˆ˜/í´ë˜ìŠ¤ëª… ë“±

        for line_idx, line_content in enumerate(lines):
            if line_content.startswith('@@'):
                import re
                match = re.search(r'\+(\d+)', line_content)
                if match:
                    current_hunk_start_line = int(match.group(1))
                    lines_in_hunk_counter = 0

                # Hunk í—¤ë”ì—ì„œ í•¨ìˆ˜/í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì •ë³´ ì¶”ì¶œ (best-effort)
                # ì˜ˆ: @@ -1,7 +1,7 @@ def my_function(param):
                # ì˜ˆ: @@ -20,5 +20,5 @@ class MyClass:
                context_match = re.search(r'@@ .* @@(.*)', line_content)
                if context_match:
                    extracted_context = context_match.group(1).strip()
                    if extracted_context and not extracted_context.startswith(('+', '-', '@')):
                         # class, def, function ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° ì»¨í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼
                        if any(kw in extracted_context.lower() for kw in ['class ', 'def ', 'function ', 'const ', 'let ', 'var ', 'module ']):
                            current_context_info = extracted_context
                        elif '(' in extracted_context and ')' in extracted_context: # ê´„í˜¸ê°€ ìˆìœ¼ë©´ í•¨ìˆ˜/ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ë¡œ ê°„ì£¼
                            current_context_info = extracted_context


                continue

            if line_content.startswith('+') and not line_content.startswith('+++'):
                actual_line_number_in_file = current_hunk_start_line + lines_in_hunk_counter
                added_line = line_content[1:].strip()

                if (added_line and
                    not added_line.startswith(('#', '//', '/*', '*', '{', '}', ')', '(')) and # ë‹¨ìˆœ ê¸°í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì œì™¸ ê°•í™”
                    len(added_line) > 10):

                    significant_changes.append({
                        'file_line_number': actual_line_number_in_file,
                        'code': added_line,
                        'context_info': current_context_info # í˜„ì¬ ì½”ë“œ ë¼ì¸ì´ ì†í•œ ì»¨í…ìŠ¤íŠ¸
                    })
                lines_in_hunk_counter +=1

            elif line_content.startswith(' ') and not line_content.startswith('---'):
                lines_in_hunk_counter +=1

        if significant_changes:
            # í˜„ì¬ íŒŒì¼ì— ì ìš©í•  ë¦¬ë·°ì–´ ê´€ì  ì„ íƒ (ìˆœí™˜)
            current_perspective = reviewer_perspectives[perspective_idx % len(reviewer_perspectives)]
            perspective_idx += 1

            line_comment_prompts = []
            for change in significant_changes[:MAX_LINE_COMMENTS_PER_FILE]: # ì„¤ì •ê°’ ì‚¬ìš© / íŒŒì¼ë‹¹ ìµœëŒ€ Nê°œ ë¼ì¸ ì½”ë©˜íŠ¸

                # ì–¸ì–´ íŠ¹í™”ì  íŒíŠ¸ ì¶”ê°€ (ì˜ˆì‹œ)
                lang_specific_hint = ""
                if file_extension == "py":
                    lang_specific_hint = "Python ì½”ë“œì˜ ê²½ìš° PEP 8 ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ë° Pythonicí•œ ì ‘ê·¼ ë°©ì‹ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”."
                elif file_extension == "js":
                    lang_specific_hint = "JavaScript ì½”ë“œì˜ ê²½ìš° ëª¨ë²” ì‚¬ë¡€(ì˜ˆ: ES6+ ë¬¸ë²•, ë¹„ë™ê¸° ì²˜ë¦¬)ë¥¼ ê³ ë ¤í•´ì£¼ì„¸ìš”."
                elif file_extension == "java":
                    lang_specific_hint = "Java ì½”ë“œì˜ ê²½ìš° ê°ì²´ ì§€í–¥ ì„¤ê³„ ì›ì¹™ ë° ì¼ë°˜ì ì¸ ì½”ë”© ì»¨ë²¤ì…˜ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”."

                line_prompt = f"""ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œ ë³€ê²½ì— ëŒ€í•´ **"{current_perspective}" ê´€ì **ì—ì„œ ì „ë¬¸ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**íŒŒì¼**: `{filename}` (ë¼ì¸: {change['file_line_number']}, ì–¸ì–´: {file_extension})
**PR ìš”êµ¬ì‚¬í•­**: {requirements}
**ì½”ë“œ ì»¨í…ìŠ¤íŠ¸**: `{change['context_info']}`

**ë³€ê²½ëœ ì½”ë“œ**:
```{file_extension}
{change['code']}
```

**ë¶„ì„ ì§€ì¹¨**:
1. **Before vs After**: ì´ ë¼ì¸ì´ ë³€ê²½ë˜ê¸° ì „ê³¼ í›„ì˜ ì°¨ì´ì ê³¼ ê·¸ ì´ìœ  ë¶„ì„
2. **ì½”ë“œ í’ˆì§ˆ**: ê°€ë…ì„±, ì„±ëŠ¥, ìœ ì§€ë³´ìˆ˜ì„±, ë³´ì•ˆ ê´€ì ì—ì„œ í‰ê°€
3. **ì–¸ì–´ë³„ íŠ¹ì„±**: {file_extension} ì–¸ì–´ì˜ ëª¨ë²” ì‚¬ë¡€ì™€ ê´€ë¡€ ì¤€ìˆ˜ ì—¬ë¶€
4. **ìš”êµ¬ì‚¬í•­ ì—°ê´€ì„±**: PR ìš”êµ¬ì‚¬í•­ê³¼ ì´ ë³€ê²½ì˜ ì—°ê´€ì„±
5. **êµ¬ì²´ì  ì œì•ˆ**: ë¬¸ì œê°€ ìˆë‹¤ë©´ ì •í™•í•œ ê°œì„  ë°©ë²• ì œì‹œ

**ì¶œë ¥ í˜•ì‹**:
- 100-150ì ë‚´ì™¸ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±
- ì‹¤ì œ ì½”ë“œë¥¼ ì¸ìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
- "{current_perspective}" ê´€ì ì— ë§ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±

**ê´€ì ë³„ ê°€ì´ë“œ**:
- positive: ì˜ëœ ì ê³¼ ì¥ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¹­ì°¬
- neutral: íŠ¸ë ˆì´ë“œì˜¤í”„ì™€ ê³ ë ¤ì‚¬í•­ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„
- critical: ë¬¸ì œì ê³¼ ê°œì„ ë°©ì•ˆì„ ëª…í™•í•˜ê²Œ ì œì‹œ

{lang_specific_hint}

í”¼ë“œë°±:"""
                line_comment_prompts.append({
                    "prompt": line_prompt,
                    "path": filename,
                    "line": change['file_line_number']
                })

            for item in line_comment_prompts:
                try:
                    response = await llm.ainvoke([SystemMessage(content=item["prompt"])])
                    ai_comment_text = response.content.strip()

                    if ai_comment_text:
                        # AIê°€ ìƒì„±í•œ í”¼ë“œë°±ì—ì„œ "í”¼ë“œë°±:" ê°™ì€ ë¶€ë¶„ì„ ì œê±°í•  ìˆ˜ ìˆë‹¤ë©´ ì¶”ê°€
                        if ai_comment_text.lower().startswith("í”¼ë“œë°±:"):
                            ai_comment_text = ai_comment_text[len("í”¼ë“œë°±:"):].strip()

                        line_comments.append({
                            "path": item["path"],
                            "line": item["line"],
                            "body": ai_comment_text
                        })
                except Exception as e:
                    _LOGGER.error(f"AI ë¼ì¸ ì½”ë©˜íŠ¸ ìƒì„± ì‹¤íŒ¨ ({item['path']} L{item['line']}): {str(e)}")
                    original_code = next((c['code'] for c in significant_changes if c['file_line_number'] == item['line']), "")
                    line_comments.append({
                        "path": item["path"],
                        "line": item["line"],
                        "body": f"ì½”ë“œ ë³€ê²½ ê°ì§€: ```{original_code[:50]}...``` (AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)[:30]})"
                    })
    _LOGGER.info(f"ìƒì„±ëœ AI ì¸ë¼ì¸ ì½”ë©˜íŠ¸ ìˆ˜: {len(line_comments)}")
    return line_comments